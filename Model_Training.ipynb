{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model_Training.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNuvO2NleS8ZTWAToT1UAty",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cargilgar/Smart-Alarm-using-tinyML/blob/main/Model_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAX4NMxXBauV"
      },
      "source": [
        "1.- Convert and reformat accelerometer data into a time-sliced representation\n",
        "\n",
        "2.- Visualize the accelerometer data\n",
        "\n",
        "3.- Reshape the multi-dimensional tabular data so that it is accepted by Keras\n",
        "\n",
        "4.- Split up the data set into training, validation, and test set\n",
        "\n",
        "5.- Define a deep neural network model in Keras which can later be processed by Apple’s Core ML\n",
        "\n",
        "6.- Train the deep neural network for human activity recognition data\n",
        "\n",
        "7.- Validate the performance of the trained DNN against the test data using learning curve and confusion matrix\n",
        "\n",
        "8.- Export the trained Keras DNN model for Core ML\n",
        "\n",
        "9.- Ensure that the Core ML model was exported correctly by conducting a sample prediction in Python\n",
        "\n",
        "\n",
        "10.- Use Apple’s Core ML library in order to predict the outcomes for a given data set using Swift"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMspG4Ee4ykf"
      },
      "source": [
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d26tssDbHuhi"
      },
      "source": [
        "# **Split Dataset**\n",
        "\n",
        "Train, Validation and Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKbziufL71Q-"
      },
      "source": [
        "def readucr(filename):\n",
        "    data = np.loadtxt(filename, delimiter=\"\\t\")\n",
        "    y = data[:, 0]\n",
        "    x = data[:, 1:]\n",
        "    return x, y.astype(int)\n",
        "\n",
        "\n",
        "root_url = \"https://raw.githubusercontent.com/hfawaz/cd-diagram/master/FordA/\"\n",
        "\n",
        "x_train, y_train = readucr(root_url + \"FordA_TRAIN.tsv\")\n",
        "x_test, y_test = readucr(root_url + \"FordA_TEST.tsv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dumte5WoIgvC"
      },
      "source": [
        "# Build the model\n",
        "We build a Convolutional Neural Network.\n",
        "The implementation is based on the TF 2 version.*texto en cursiva*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhJpl6hlIf42"
      },
      "source": [
        "def make_model(input_shape):\n",
        "    input_layer = keras.layers.Input(input_shape)\n",
        "\n",
        "    conv1 = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(input_layer)\n",
        "    conv1 = keras.layers.BatchNormalization()(conv1)\n",
        "    conv1 = keras.layers.ReLU()(conv1)\n",
        "\n",
        "    conv2 = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(conv1)\n",
        "    conv2 = keras.layers.BatchNormalization()(conv2)\n",
        "    conv2 = keras.layers.ReLU()(conv2)\n",
        "\n",
        "    conv3 = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(conv2)\n",
        "    conv3 = keras.layers.BatchNormalization()(conv3)\n",
        "    conv3 = keras.layers.ReLU()(conv3)\n",
        "\n",
        "    gap = keras.layers.GlobalAveragePooling1D()(conv3)\n",
        "\n",
        "    output_layer = keras.layers.Dense(num_classes, activation=\"softmax\")(gap)\n",
        "\n",
        "    return keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "\n",
        "model = make_model(input_shape=x_train.shape[1:])\n",
        "keras.utils.plot_model(model, show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}