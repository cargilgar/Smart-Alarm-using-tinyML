{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Model_Training.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyPiqf9IHaVp6zgA1XjeSxL/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"5iB8fV6iWeQs","executionInfo":{"status":"ok","timestamp":1622720661138,"user_tz":-120,"elapsed":2238,"user":{"displayName":"Daniel Moreno","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiN-vX7mNsnTms9a2ZACAxsu0C62vmQUNoWZz60MP0=s64","userId":"03239533346995134647"}}},"source":["import pandas as pd\n","import numpy as np\n","import os\n","import re\n","from scipy import stats\n","from keras.models import Sequential\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from keras.layers import Dense"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1R0wTJdcZzA9"},"source":["# Load Dataset\n","\n","Load Dataset, count Rows and Columns"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uge8UaRLVvuT","executionInfo":{"status":"ok","timestamp":1622720661139,"user_tz":-120,"elapsed":5,"user":{"displayName":"Daniel Moreno","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiN-vX7mNsnTms9a2ZACAxsu0C62vmQUNoWZz60MP0=s64","userId":"03239533346995134647"}},"outputId":"f11dd5d7-e104-4412-b573-bf7126190405"},"source":["data_path = os.path.join(os.getcwd(), \"dataset/\")\n","data_list = sorted(os.listdir(data_path))\n","data_list[0]\n","\n","\n","subject_csv = pd.read_csv(os.path.join(data_path, data_list[0]), delimiter=',')\n","subject_csv\n","\n","#Rows and Columns\n","total_rows=len(subject_csv.axes[0]) #===> Axes of 0 is for a row\n","total_cols=len(subject_csv.axes[1]) #===> Axes of 1 is for a column\n","print(\"Number of Rows: \"+str(total_rows))\n","print(\"Number of Columns: \"+str(total_cols))\n","\n","#subject_csv"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Number of Rows: 50\n","Number of Columns: 6\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"00jGhBmxqSXE"},"source":["# Labels\n","stage (0-5, wake = 0, N1 = 1, N2 = 2, N3 = 3, REM = 5)"]},{"cell_type":"code","metadata":{"id":"uw3S8hjGdj0T","executionInfo":{"status":"ok","timestamp":1622720663516,"user_tz":-120,"elapsed":202,"user":{"displayName":"Daniel Moreno","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiN-vX7mNsnTms9a2ZACAxsu0C62vmQUNoWZz60MP0=s64","userId":"03239533346995134647"}}},"source":["#Show labels\n","# Same labels will be reused throughout the program\n","\n","subject_csv['labels'].describe()\n","#subject_csv.hist('Heart Rate')\n","#subject_csv.describe()\n","'''\n","subject_csv['labels'] = subject_csv['labels'].map({0:'Wake',\n","                             1:'NREM',\n","                             2:'NREM',\n","                             3:'NREM',\n","                             5:'REM',\n","                             },\n","                             na_action=None)\n","'''\n","subject_csv['labels'] = subject_csv['labels'].map({0:0,\n","                             1:1,\n","                             2:1,\n","                             3:1,\n","                             5:2,\n","                             },\n","                             na_action=None)\n","\n","#Delete non-labeled Rows\n","subject_csv.dropna(inplace=True)\n","\n","#Not labeled values --> NaN\n","\n","#subject_csv"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oC7ObCbBZ_1-"},"source":["# Split Dataset\n","Train, Validation and Test\n","\n","Split the data\n","We'll use a (70%, 20%, 10%) split for the training, validation, and test sets. Note the data is not being randomly shuffled before splitting. This is for two reasons.\n","\n","It ensures that chopping the data into windows of consecutive samples is still possible.\n","It ensures that the validation/test results are more realistic, being evaluated on data collected after the model was trained.\n","\n","***ANOTHER SPLITING OPTION WOULD BE TO SEPARATE USERS (Crear nueva columna con nombre usuario?? O manejar cada CSV por separado??)***\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"DUcpsQLZaKOE","executionInfo":{"status":"ok","timestamp":1622720666203,"user_tz":-120,"elapsed":210,"user":{"displayName":"Daniel Moreno","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiN-vX7mNsnTms9a2ZACAxsu0C62vmQUNoWZz60MP0=s64","userId":"03239533346995134647"}}},"source":["column_indices = {name: i for i, name in enumerate(subject_csv.columns)}\n","\n","PERCENTAGE_TRAIN = 0.7\n","PERCENTAGE_VALIDATION = 0.2\n","\n","n = len(subject_csv)\n","train_subject_csv = subject_csv[0:int(n*PERCENTAGE_TRAIN)]\n","val_subject_csv = subject_csv[int(n*PERCENTAGE_TRAIN):int(n*(PERCENTAGE_VALIDATION + PERCENTAGE_TRAIN))]\n","test_subject_csv = subject_csv[int(n*(PERCENTAGE_VALIDATION + PERCENTAGE_TRAIN)):]\n","\n","num_features = subject_csv.shape[1]\n","#test_subject_csv"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VwnxK53835FY"},"source":["# Normalize Training Data\n","Next, we need to normalize our features within our training data. Of course there are various ways on how to normalize. Please keep in mind that you use the same normalization algorithm later when feeding new data into your neural network. Otherwise your preditions will be off. On top of the normalization we will also apply rounding to the three features.\n","\n","*CORREGIR VALORES NEGATIVOS*"]},{"cell_type":"code","metadata":{"id":"bOd1dXMi2N4_","executionInfo":{"status":"ok","timestamp":1622720669177,"user_tz":-120,"elapsed":199,"user":{"displayName":"Daniel Moreno","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiN-vX7mNsnTms9a2ZACAxsu0C62vmQUNoWZz60MP0=s64","userId":"03239533346995134647"}}},"source":["# Normalize features for training data set (values between 0 and 1)***\n","# Surpress warning for next 3 operation\n","pd.options.mode.chained_assignment = None  # default='warn'\n","train_subject_csv['X'] = train_subject_csv['X'] / train_subject_csv['X'].max()\n","train_subject_csv['Y'] = train_subject_csv['Y'] / train_subject_csv['Y'].max()\n","train_subject_csv['Z'] = train_subject_csv['Z'] / train_subject_csv['Z'].max()\n","train_subject_csv['Heart Rate'] = train_subject_csv['Heart Rate'] / train_subject_csv['Heart Rate'].max()\n","\n","# Round numbers (4 decimals)\n","train_subject_csv = train_subject_csv.round({'X': 4, 'Y': 4, 'Z': 4, 'Heart Rate': 4})\n","\n","#train_subject_csv"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aYGO3D4b7btV"},"source":["# Reshape Data into Segments and Prepare for Keras\n","The data contained in the dataframe is not ready yet to be fed into a neural network. Therefore we need to reshape it. Let’s create another function for this called “create_segments_and_labels”. This function will take in the dataframe and the label names (the constant that we have defined at the beginning) as well as the length of each record. In our case, let’s go with 80 steps (see constant defined earlier). Taking into consideration the 20 Hz sampling rate, this equals to 4 second time intervals (calculation: 0.05 * 80 = 4). Besides reshaping the data, the function will also separate the features (x-acceleration, y-acceleration, z-acceleration) and the labels (associated activity). https://towardsdatascience.com/human-activity-recognition-har-tutorial-with-keras-and-core-ml-part-1-8c05e365dfa0"]},{"cell_type":"code","metadata":{"id":"2jOMBw867eW2","executionInfo":{"status":"ok","timestamp":1622720670988,"user_tz":-120,"elapsed":198,"user":{"displayName":"Daniel Moreno","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiN-vX7mNsnTms9a2ZACAxsu0C62vmQUNoWZz60MP0=s64","userId":"03239533346995134647"}}},"source":["def create_segments_and_labels(subject_csv,labels):\n","\n","    labels = subject_csv[labels]\n","    segments = subject_csv[['X','Y','Z','Heart Rate']]\n","\n","    return segments, labels"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"ODyG2FBGAGd6","executionInfo":{"status":"ok","timestamp":1622720671977,"user_tz":-120,"elapsed":331,"user":{"displayName":"Daniel Moreno","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiN-vX7mNsnTms9a2ZACAxsu0C62vmQUNoWZz60MP0=s64","userId":"03239533346995134647"}}},"source":["# x_train --> Features\n","# y_train --> Labels\n","   \n","x_train, y_train = create_segments_and_labels(train_subject_csv,'labels')\n","x_val, y_val = create_segments_and_labels(val_subject_csv,'labels')\n","x_test, y_test = create_segments_and_labels(test_subject_csv,'labels')\n"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q_6uxZqJTOTx","executionInfo":{"status":"ok","timestamp":1622720672806,"user_tz":-120,"elapsed":3,"user":{"displayName":"Daniel Moreno","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiN-vX7mNsnTms9a2ZACAxsu0C62vmQUNoWZz60MP0=s64","userId":"03239533346995134647"}},"outputId":"73f2d657-053e-48ba-b6e4-6d9a01a4b487"},"source":["print(x_train.shape[0], 'training samples')\n","print('x_train shape: ', x_train.shape)\n","print('y_train shape: ', y_train.shape)\n","x_train.shape[0]\n","#x_train.shape[1]"],"execution_count":8,"outputs":[{"output_type":"stream","text":["32 training samples\n","x_train shape:  (32, 4)\n","y_train shape:  (32,)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["32"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"mCXw2xaUJQ_l"},"source":["# Create Deep Neural Network Model in Keras\n"]},{"cell_type":"code","metadata":{"id":"-DyMELaTeUqD","executionInfo":{"status":"ok","timestamp":1622720674495,"user_tz":-120,"elapsed":199,"user":{"displayName":"Daniel Moreno","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiN-vX7mNsnTms9a2ZACAxsu0C62vmQUNoWZz60MP0=s64","userId":"03239533346995134647"}}},"source":["# define the keras model\n","model = Sequential()\n","model.add(Dense(20, input_dim= x_train.shape[1], activation=\"relu\"))\n","model.add(Dense(8, activation=\"relu\"))\n","model.add(Dense(3, activation=\"softmax\")) #Last layer corresponds with the number of possible outputs\n"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1k6aRyPof6cc","executionInfo":{"status":"ok","timestamp":1622720677008,"user_tz":-120,"elapsed":218,"user":{"displayName":"Daniel Moreno","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiN-vX7mNsnTms9a2ZACAxsu0C62vmQUNoWZz60MP0=s64","userId":"03239533346995134647"}},"outputId":"a60df363-dcf2-4f42-c71e-c033a2bd3a0b"},"source":["# compile the keras model\n","model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","model.summary()"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense (Dense)                (None, 20)                100       \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 8)                 168       \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 3)                 27        \n","=================================================================\n","Total params: 295\n","Trainable params: 295\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"z7L-f61Kr9Qm"},"source":["# Train Model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O1byX-NigRhU","executionInfo":{"status":"ok","timestamp":1622720695035,"user_tz":-120,"elapsed":15490,"user":{"displayName":"Daniel Moreno","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiN-vX7mNsnTms9a2ZACAxsu0C62vmQUNoWZz60MP0=s64","userId":"03239533346995134647"}},"outputId":"0714ba63-f875-4aad-e673-bff6c4c64af5"},"source":["# fit the keras model on the dataset\n","model.fit(x_train, y_train, epochs=150, batch_size=10)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Epoch 1/150\n","4/4 [==============================] - 12s 3ms/step - loss: 1.0776 - accuracy: 0.4017\n","Epoch 2/150\n","4/4 [==============================] - 0s 3ms/step - loss: 1.0635 - accuracy: 0.4283\n","Epoch 3/150\n","4/4 [==============================] - 0s 4ms/step - loss: 1.0526 - accuracy: 0.4383\n","Epoch 4/150\n","4/4 [==============================] - 0s 4ms/step - loss: 1.0405 - accuracy: 0.4083\n","Epoch 5/150\n","4/4 [==============================] - 0s 2ms/step - loss: 1.0276 - accuracy: 0.4842\n","Epoch 6/150\n","4/4 [==============================] - 0s 2ms/step - loss: 1.0032 - accuracy: 0.8442\n","Epoch 7/150\n","4/4 [==============================] - 0s 4ms/step - loss: 0.9868 - accuracy: 0.8042\n","Epoch 8/150\n","4/4 [==============================] - 0s 2ms/step - loss: 0.9645 - accuracy: 0.8542\n","Epoch 9/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.9370 - accuracy: 0.9008\n","Epoch 10/150\n","4/4 [==============================] - 0s 4ms/step - loss: 0.9166 - accuracy: 0.8842\n","Epoch 11/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.8900 - accuracy: 0.8442\n","Epoch 12/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.8558 - accuracy: 0.8508\n","Epoch 13/150\n","4/4 [==============================] - 0s 2ms/step - loss: 0.8361 - accuracy: 0.8242\n","Epoch 14/150\n","4/4 [==============================] - 0s 2ms/step - loss: 0.8121 - accuracy: 0.7742\n","Epoch 15/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.7652 - accuracy: 0.8642\n","Epoch 16/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.7246 - accuracy: 0.8642\n","Epoch 17/150\n","4/4 [==============================] - 0s 2ms/step - loss: 0.6981 - accuracy: 0.8542\n","Epoch 18/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.6684 - accuracy: 0.8608\n","Epoch 19/150\n","4/4 [==============================] - 0s 2ms/step - loss: 0.6243 - accuracy: 0.9042\n","Epoch 20/150\n","4/4 [==============================] - 0s 2ms/step - loss: 0.6277 - accuracy: 0.8508\n","Epoch 21/150\n","4/4 [==============================] - 0s 2ms/step - loss: 0.6188 - accuracy: 0.8242\n","Epoch 22/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.5738 - accuracy: 0.8842\n","Epoch 23/150\n","4/4 [==============================] - 0s 2ms/step - loss: 0.5782 - accuracy: 0.8642\n","Epoch 24/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.5422 - accuracy: 0.8742\n","Epoch 25/150\n","4/4 [==============================] - 0s 2ms/step - loss: 0.5592 - accuracy: 0.8342\n","Epoch 26/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.5272 - accuracy: 0.8542\n","Epoch 27/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.5154 - accuracy: 0.8542\n","Epoch 28/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.5243 - accuracy: 0.8242\n","Epoch 29/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.5036 - accuracy: 0.8442\n","Epoch 30/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.5125 - accuracy: 0.8242\n","Epoch 31/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.4558 - accuracy: 0.8608\n","Epoch 32/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.4245 - accuracy: 0.8842\n","Epoch 33/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.4696 - accuracy: 0.8408\n","Epoch 34/150\n","4/4 [==============================] - 0s 4ms/step - loss: 0.4597 - accuracy: 0.8508\n","Epoch 35/150\n","4/4 [==============================] - 0s 4ms/step - loss: 0.4518 - accuracy: 0.8542\n","Epoch 36/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.5122 - accuracy: 0.8042\n","Epoch 37/150\n","4/4 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.8342\n","Epoch 38/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.4264 - accuracy: 0.8608\n","Epoch 39/150\n","4/4 [==============================] - 0s 2ms/step - loss: 0.4478 - accuracy: 0.8408\n","Epoch 40/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.3859 - accuracy: 0.8808\n","Epoch 41/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.4844 - accuracy: 0.8108\n","Epoch 42/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.4762 - accuracy: 0.8142\n","Epoch 43/150\n","4/4 [==============================] - 0s 4ms/step - loss: 0.4602 - accuracy: 0.8242\n","Epoch 44/150\n","4/4 [==============================] - 0s 4ms/step - loss: 0.4780 - accuracy: 0.8142\n","Epoch 45/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.4579 - accuracy: 0.8242\n","Epoch 46/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.3718 - accuracy: 0.8842\n","Epoch 47/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.4433 - accuracy: 0.8242\n","Epoch 48/150\n","4/4 [==============================] - 0s 4ms/step - loss: 0.3444 - accuracy: 0.8942\n","Epoch 49/150\n","4/4 [==============================] - 0s 4ms/step - loss: 0.4317 - accuracy: 0.8342\n","Epoch 50/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.4256 - accuracy: 0.8342\n","Epoch 51/150\n","4/4 [==============================] - 0s 4ms/step - loss: 0.4201 - accuracy: 0.8442\n","Epoch 52/150\n","4/4 [==============================] - 0s 7ms/step - loss: 0.3373 - accuracy: 0.8942\n","Epoch 53/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.4819 - accuracy: 0.8042\n","Epoch 54/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.4180 - accuracy: 0.8442\n","Epoch 55/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.4352 - accuracy: 0.8242\n","Epoch 56/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.3595 - accuracy: 0.8742\n","Epoch 57/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.4385 - accuracy: 0.8242\n","Epoch 58/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.4042 - accuracy: 0.8442\n","Epoch 59/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.3723 - accuracy: 0.8675\n","Epoch 60/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.4364 - accuracy: 0.8242\n","Epoch 61/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.4308 - accuracy: 0.8242\n","Epoch 62/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.3925 - accuracy: 0.8542\n","Epoch 63/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.3164 - accuracy: 0.8975\n","Epoch 64/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.3935 - accuracy: 0.8442\n","Epoch 65/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.3602 - accuracy: 0.8708\n","Epoch 66/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.4460 - accuracy: 0.8142\n","Epoch 67/150\n","4/4 [==============================] - 0s 4ms/step - loss: 0.3962 - accuracy: 0.8442\n","Epoch 68/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.5017 - accuracy: 0.7742\n","Epoch 69/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.3669 - accuracy: 0.8542\n","Epoch 70/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.3981 - accuracy: 0.8442\n","Epoch 71/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.4588 - accuracy: 0.7942\n","Epoch 72/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.3768 - accuracy: 0.8542\n","Epoch 73/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.3139 - accuracy: 0.8942\n","Epoch 74/150\n","4/4 [==============================] - 0s 4ms/step - loss: 0.4000 - accuracy: 0.8442\n","Epoch 75/150\n","4/4 [==============================] - 0s 2ms/step - loss: 0.4496 - accuracy: 0.8042\n","Epoch 76/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.3447 - accuracy: 0.8708\n","Epoch 77/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.3154 - accuracy: 0.8842\n","Epoch 78/150\n","4/4 [==============================] - 0s 2ms/step - loss: 0.4562 - accuracy: 0.7942\n","Epoch 79/150\n","4/4 [==============================] - 0s 4ms/step - loss: 0.3243 - accuracy: 0.8808\n","Epoch 80/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.4323 - accuracy: 0.8142\n","Epoch 81/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.3560 - accuracy: 0.8642\n","Epoch 82/150\n","4/4 [==============================] - 0s 4ms/step - loss: 0.3338 - accuracy: 0.8808\n","Epoch 83/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.3700 - accuracy: 0.8508\n","Epoch 84/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.3352 - accuracy: 0.8808\n","Epoch 85/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.4914 - accuracy: 0.7742\n","Epoch 86/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.3535 - accuracy: 0.8642\n","Epoch 87/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.3879 - accuracy: 0.8442\n","Epoch 88/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.4111 - accuracy: 0.8308\n","Epoch 89/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.3437 - accuracy: 0.8642\n","Epoch 90/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.3898 - accuracy: 0.8308\n","Epoch 91/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.3088 - accuracy: 0.8942\n","Epoch 92/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.4057 - accuracy: 0.8442\n","Epoch 93/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.4337 - accuracy: 0.8142\n","Epoch 94/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.3624 - accuracy: 0.8608\n","Epoch 95/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.3956 - accuracy: 0.8342\n","Epoch 96/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.3724 - accuracy: 0.8542\n","Epoch 97/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.4292 - accuracy: 0.8142\n","Epoch 98/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.4127 - accuracy: 0.8242\n","Epoch 99/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.4172 - accuracy: 0.8242\n","Epoch 100/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.4159 - accuracy: 0.8208\n","Epoch 101/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.4113 - accuracy: 0.8242\n","Epoch 102/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.3813 - accuracy: 0.8442\n","Epoch 103/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.4038 - accuracy: 0.8408\n","Epoch 104/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.3569 - accuracy: 0.8642\n","Epoch 105/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.3462 - accuracy: 0.8642\n","Epoch 106/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.2929 - accuracy: 0.9008\n","Epoch 107/150\n","4/4 [==============================] - 0s 4ms/step - loss: 0.3435 - accuracy: 0.8708\n","Epoch 108/150\n","4/4 [==============================] - 0s 6ms/step - loss: 0.3549 - accuracy: 0.8642\n","Epoch 109/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.3359 - accuracy: 0.8742\n","Epoch 110/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.4454 - accuracy: 0.7942\n","Epoch 111/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.4590 - accuracy: 0.8042\n","Epoch 112/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.3298 - accuracy: 0.8742\n","Epoch 113/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.4408 - accuracy: 0.8042\n","Epoch 114/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.3491 - accuracy: 0.8742\n","Epoch 115/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.3815 - accuracy: 0.8408\n","Epoch 116/150\n","4/4 [==============================] - 0s 4ms/step - loss: 0.3797 - accuracy: 0.8442\n","Epoch 117/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.3542 - accuracy: 0.8608\n","Epoch 118/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.4145 - accuracy: 0.8142\n","Epoch 119/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.4173 - accuracy: 0.8242\n","Epoch 120/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.3722 - accuracy: 0.8408\n","Epoch 121/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.4354 - accuracy: 0.8042\n","Epoch 122/150\n","4/4 [==============================] - 0s 4ms/step - loss: 0.3446 - accuracy: 0.8608\n","Epoch 123/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.3578 - accuracy: 0.8642\n","Epoch 124/150\n","4/4 [==============================] - 0s 4ms/step - loss: 0.3912 - accuracy: 0.8342\n","Epoch 125/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.4097 - accuracy: 0.8242\n","Epoch 126/150\n","4/4 [==============================] - 0s 4ms/step - loss: 0.4208 - accuracy: 0.8242\n","Epoch 127/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.3603 - accuracy: 0.8542\n","Epoch 128/150\n","4/4 [==============================] - 0s 4ms/step - loss: 0.3828 - accuracy: 0.8408\n","Epoch 129/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.3601 - accuracy: 0.8542\n","Epoch 130/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.3936 - accuracy: 0.8442\n","Epoch 131/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.3364 - accuracy: 0.8742\n","Epoch 132/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.4418 - accuracy: 0.8042\n","Epoch 133/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.4212 - accuracy: 0.8208\n","Epoch 134/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.3747 - accuracy: 0.8542\n","Epoch 135/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.3565 - accuracy: 0.8642\n","Epoch 136/150\n","4/4 [==============================] - 0s 4ms/step - loss: 0.3658 - accuracy: 0.8608\n","Epoch 137/150\n","4/4 [==============================] - 0s 4ms/step - loss: 0.3816 - accuracy: 0.8542\n","Epoch 138/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.3259 - accuracy: 0.8842\n","Epoch 139/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.3862 - accuracy: 0.8342\n","Epoch 140/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.4669 - accuracy: 0.7842\n","Epoch 141/150\n","4/4 [==============================] - 0s 4ms/step - loss: 0.3257 - accuracy: 0.8808\n","Epoch 142/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.4460 - accuracy: 0.8042\n","Epoch 143/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.3178 - accuracy: 0.8808\n","Epoch 144/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.4571 - accuracy: 0.7908\n","Epoch 145/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.4149 - accuracy: 0.8208\n","Epoch 146/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.3713 - accuracy: 0.8442\n","Epoch 147/150\n","4/4 [==============================] - 0s 3ms/step - loss: 0.4115 - accuracy: 0.8242\n","Epoch 148/150\n","4/4 [==============================] - 0s 4ms/step - loss: 0.3241 - accuracy: 0.8742\n","Epoch 149/150\n","4/4 [==============================] - 0s 6ms/step - loss: 0.3735 - accuracy: 0.8442\n","Epoch 150/150\n","4/4 [==============================] - 0s 5ms/step - loss: 0.4499 - accuracy: 0.7842\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f154fd909d0>"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"b7wDeVitsAE-"},"source":["# Evaluate Model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6Ew4p3YooK3m","executionInfo":{"status":"ok","timestamp":1622720695571,"user_tz":-120,"elapsed":540,"user":{"displayName":"Daniel Moreno","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiN-vX7mNsnTms9a2ZACAxsu0C62vmQUNoWZz60MP0=s64","userId":"03239533346995134647"}},"outputId":"9e53c81f-70a5-4b5d-a3f8-3580af8b3799"},"source":["# evaluate the keras model\n","model.evaluate(x_test, y_test)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["1/1 [==============================] - 1s 552ms/step - loss: 65.0143 - accuracy: 0.8000\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[65.0142593383789, 0.800000011920929]"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"aH0VCbDGO5G4"},"source":["# Fit the DNN Model in Keras\n","Next, we will train the model with our training data that we have prepared earlier. We will define an early stopping callback monitor on training accuracy: if the training fails to improve for two consecutive epochs, then the training will stop with the best model. The hyperparameter used for the training are quite simple: We will use a batch size of 400 records and will train the model for 50 epochs. For model training, we will use a 80:20 split to separate training data and validation data. It is that simple. So let’s go ahead and train our model. There are some good explanations out there on the different hyperparameters, for instance here (https://towardsdatascience.com/epoch-vs-iterations-vs-batch-size-4dfb9c7ce9c9)."]},{"cell_type":"code","metadata":{"id":"8r6NGtfrO_Qa"},"source":["callbacks_list = [\n","    keras.callbacks.ModelCheckpoint(\n","        filepath='best_model.{epoch:02d}-{val_loss:.2f}.h5',\n","        monitor='val_loss', save_best_only=True),\n","    keras.callbacks.EarlyStopping(monitor='acc', patience=1)\n","]\n","\n","model_m.compile(loss='categorical_crossentropy',\n","                optimizer='adam', metrics=['accuracy'])\n","\n","# Hyper-parameters\n","BATCH_SIZE = 400\n","EPOCHS = 50\n","\n","# Enable validation to use ModelCheckpoint and EarlyStopping callbacks.\n","history = model_m.fit(x_train,\n","                      y_train_hot,\n","                      batch_size=BATCH_SIZE,\n","                      epochs=EPOCHS,\n","                      callbacks=callbacks_list,\n","                      validation_split=0.2,\n","                      verbose=1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7uAf9jsdJaEG"},"source":["\n","\n","---\n","\n","\n","\n","---\n","\n","\n","\n","---\n","\n","\n","\n","\n","---\n","\n","\n","\n","---\n","\n","\n","\n","---\n","\n","\n","\n","---\n","\n","\n","\n","---\n","\n","\n","\n","---\n","\n","\n","\n","---\n","\n","\n","\n","---\n","\n","\n","\n","---\n","\n","\n","---\n","\n","\n","\n","---\n","\n","\n","\n","---\n","\n","\n","\n","---\n","\n","\n","\n","---\n","\n","\n","---\n","\n","\n","\n","---\n","\n","\n","\n","---\n","\n","\n","\n","---\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"qC30xxnNJ70d"},"source":["# Standarize the data\n","Our timeseries are already in a single length (176). However, their values are usually in various ranges. This is not ideal for a neural network; in general we should seek to make the input values normalized. For this specific dataset, the data is already z-normalized: each timeseries sample has a mean equal to zero and a standard deviation equal to one. This type of normalization is very common for timeseries classification problems, see Bagnall et al. (2016).\n","\n","Note that the timeseries data used here are univariate, meaning we only have one channel per timeseries example. We will therefore transform the timeseries into a multivariate one with one channel using a simple reshaping via numpy. This will allow us to construct a model that is easily applicable to multivariate time series."]},{"cell_type":"markdown","metadata":{"id":"R8rIsZeKKNnA"},"source":["Finally, in order to use sparse_categorical_crossentropy, we will have to count the number of classes beforehand."]},{"cell_type":"markdown","metadata":{"id":"6G7kPrQWKL88"},"source":["Now we shuffle the training set because we will be using the validation_split option later when training."]},{"cell_type":"code","metadata":{"id":"APAAU9zoKGCt"},"source":["idx = np.random.permutation(len(x_train))\n","x_train = x_train[idx]\n","y_train = y_train[idx]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EHGEVuCTKKVq"},"source":["Standardize the labels to positive integers. The expected labels will then be 0 and 1."]},{"cell_type":"code","metadata":{"id":"eJXDNZFNKHoY"},"source":["y_train[y_train == -1] = 0\n","y_test[y_test == -1] = 0"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rZ9krAqfKT6Y"},"source":["# Visualize the data\n","Here we visualize one timeseries example for each class in the dataset."]},{"cell_type":"code","metadata":{"id":"BF44xXwsKSfo"},"source":["classes = np.unique(np.concatenate((y_train, y_test), axis=0))\n","\n","plt.figure()\n","for c in classes:\n","    c_x_train = x_train[y_train == c]\n","    plt.plot(c_x_train[0], label=\"class \" + str(c))\n","plt.legend(loc=\"best\")\n","plt.show()\n","plt.close()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Dumte5WoIgvC"},"source":["# Build the model\n"]},{"cell_type":"code","metadata":{"id":"ZhJpl6hlIf42"},"source":["module_selection = (\"mobilenet_v2\", 224, 1280) \n","handle_base, pixels, FV_SIZE = module_selection\n","MODULE_HANDLE =\"https://tfhub.dev/google/tf2-preview/{}/feature_vector/4\".format(handle_base)\n","IMAGE_SIZE = (pixels, pixels)\n","print(\"Using {} with input size {} and output dimension {}\".format(MODULE_HANDLE, IMAGE_SIZE, FV_SIZE))\n","\n","feature_extractor = hub.KerasLayer(MODULE_HANDLE,\n","                                   input_shape=IMAGE_SIZE + (3,), \n","                                   output_shape=[FV_SIZE],\n","                                   trainable=False)\n","\n","print(\"Building model with\", MODULE_HANDLE)\n","\n","model = tf.keras.Sequential([\n","        feature_extractor,\n","        tf.keras.layers.Dense(num_classes, activation='softmax')\n","])\n","\n","model.summary()\n","\n","model.compile(optimizer='adam',\n","                  loss='sparse_categorical_crossentropy',\n","                  metrics=['accuracy'])\n","\n","EPOCHS = 15\n","\n","hist = model.fit(train_batches,\n","                 epochs=EPOCHS,\n","                 validation_data=validation_batches)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xM_JiOZBJLV7"},"source":["# Train the model"]},{"cell_type":"code","metadata":{"id":"w2HhwnDHJKBN"},"source":["epochs = 500\n","batch_size = 32\n","\n","callbacks = [\n","    keras.callbacks.ModelCheckpoint(\n","        \"best_model.h5\", save_best_only=True, monitor=\"val_loss\"\n","    ),\n","    keras.callbacks.ReduceLROnPlateau(\n","        monitor=\"val_loss\", factor=0.5, patience=20, min_lr=0.0001\n","    ),\n","    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=50, verbose=1),\n","]\n","model.compile(\n","    optimizer=\"adam\",\n","    loss=\"sparse_categorical_crossentropy\",\n","    metrics=[\"sparse_categorical_accuracy\"],\n",")\n","history = model.fit(\n","    x_train,\n","    y_train,\n","    batch_size=batch_size,\n","    epochs=epochs,\n","    callbacks=callbacks,\n","    validation_split=0.2,\n","    verbose=1,\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dRqTDxxCJPIH"},"source":["# Evaluate model on test data"]},{"cell_type":"code","metadata":{"id":"37V5g3CgJOoY"},"source":["model = keras.models.load_model(\"best_model.h5\")\n","\n","test_loss, test_acc = model.evaluate(x_test, y_test)\n","\n","print(\"Test accuracy\", test_acc)\n","print(\"Test loss\", test_loss)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4uBd2AhxJUMN"},"source":["# Plot the model's training and validation loss"]},{"cell_type":"code","metadata":{"id":"k731PX_QJTr9"},"source":["metric = \"sparse_categorical_accuracy\"\n","plt.figure()\n","plt.plot(history.history[metric])\n","plt.plot(history.history[\"val_\" + metric])\n","plt.title(\"model \" + metric)\n","plt.ylabel(metric, fontsize=\"large\")\n","plt.xlabel(\"epoch\", fontsize=\"large\")\n","plt.legend([\"train\", \"val\"], loc=\"best\")\n","plt.show()\n","plt.close()"],"execution_count":null,"outputs":[]}]}